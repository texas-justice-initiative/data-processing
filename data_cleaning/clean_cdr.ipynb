{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and reformat CDR data from its multi-tab excel file into a single csv\n",
    "\n",
    "### About the data\n",
    "\n",
    "CDR data is tricky -- the form used by law enforcement has changed over time, first in 2005, then again in 2016. The data before 2005 is known to be be sparse and poorly enforced, so we ignore those entries. The 2005 and 2016 versions of the form have some overlap and some differences, so we must be careful in how we merge them.\n",
    "\n",
    "Further, some older deaths that happened in an inpatient setting are not reported in these dataset. In the past, for the first version of the TJI website, these records were requested. We have an \"old master file\" that was used in the first TJI website that includes these deaths, but also many others. We need to load this file and include any records that we don't yet have.\n",
    "\n",
    "**In this repo you can find blank versions of the [2005](https://github.com/texas-justice-initiative/data-processing/blob/master/forms/CDR%20Form%20Version%202005.pdf) and [2016](https://github.com/texas-justice-initiative/data-processing/blob/master/forms/CDR%20Form%20Version%202016.pdf) forms, to see for yourself exactly what fields are collected and how.**\n",
    "\n",
    "### Datasets used\n",
    "\n",
    "\n",
    "* Input:\n",
    "  * `tji/raw-and-processing/CDR - All Reports.xlsx`\n",
    "  * `tji/raw-and-processing/reformatted_cdr_2017_master_file`\n",
    "  * `tji/auxiliary-datasets/agencies_and_counties`\n",
    "* Output:\n",
    "  * `tji/deaths-in-custody/cleaned_custodial_death_reports.csv`\n",
    "  \n",
    "##### Author: Everett Wetchler (everett.wetchler@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "\n",
    "**1. Setup and read data**\n",
    "- 1a. Configuration and imports\n",
    "    - Constants\n",
    "    - Libraries\n",
    "- 1.b Read data\n",
    "    - Drop records with death date pre-2005\n",
    "- 1c. Helper methods/code\n",
    "    \n",
    "\n",
    "**2. Join disparate datasets, rename and reformat columns**\n",
    "- 2a. Reduce columns used and rename\n",
    "    - Drop columns that we either don't need or haven't written code to clean yet\n",
    "    - Rename columns to be more machine friendly\n",
    "- 2b. Add rows from the old master file to get BJS inpatient deaths \n",
    "    - Merge the \"old master\" file with the other CDR records\n",
    "- 2c. Column type conversions\n",
    "    - Convert date columns\n",
    "    - Float columns covert from string\n",
    "    - Upcase string columns\n",
    "    - Add `death_date` column\n",
    "    \n",
    "**3. Begin Deep Cleaning**\n",
    "- 3a. Standardize `race` values\n",
    "- 3b. Standardize agency information\n",
    "- 3c. Fix death-information related columns\n",
    "    - Fix `Death Location`\n",
    "    - fix `Means of Death`\n",
    "    - Fix `manner_of_death` and `manner of death`\n",
    "    - Fix `pre_existing_medical_condition`\n",
    "    - Fix `who_caused_the_death`\n",
    "    - Fix `medical_examinor_coroner_evalution`\n",
    "- 3d. Fix other columns one-by-one\n",
    "    - Standardize `gender`\n",
    "    - Fix `were_there_charges`\n",
    "    - Fix `type_of_custody`\n",
    "    - Fix `specific_type_of_custody_facility`\n",
    "- 3e. Identify and drop a range of unnecessary columns\n",
    "    - `entry_date_time_n_a` and `custody_date_na`\n",
    "    - `department_type`\n",
    "\n",
    "**4. Deduplication**\n",
    "- 4a. Whole row duplicates\n",
    "- 4b. Define some dedup functions\n",
    "- 4c. Dedup\n",
    "- 4d. Inspect results\n",
    "\n",
    "**5. Add new columns, rename/reorder, otherwise finalize dataframe**\n",
    "- 5a. New columns and bookkeeping columns\n",
    "    - Column for the time (in days) between incarceration (or incident) and death\n",
    "- 5b. Rename and reorder columns sensibly\n",
    "- 5c. Final look before writing\n",
    "\n",
    "\n",
    "**6. Write**\n",
    "\n",
    "\n",
    "**7. TODOs -- problems that still exist in the data and need work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's begin..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 1. Setup and read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 20px\"></div>\n",
    "\n",
    "## 1a. Configuration and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:50.498617Z",
     "start_time": "2020-11-15T16:28:50.495521Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants so we don't have to hunt through the code to tweak these in many places\n",
    "\n",
    "DW_PROJECT_CDR = 'tji/deaths-in-custody'\n",
    "DW_PROJECT_OIS = 'tji/officer-involved-shootings'\n",
    "DW_PROJECT_AUXILIARY_DATASETS = 'tji/auxiliary-datasets'\n",
    "DW_PROJECT_RAW_AND_PROCESSING = 'tji/raw-and-processing'\n",
    "\n",
    "OUTPUT_DW_PROJECT = DW_PROJECT_CDR\n",
    "OUTPUT_FILENAME = 'cleaned_custodial_death_reports.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:31:53.375428Z",
     "start_time": "2020-11-15T16:31:53.356893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Everett Wetchler, Aiden Yang 2020-11-15 09:31:53 MST \n",
      "\n",
      "numpy 1.17.2\n",
      "pandas 1.1.2\n",
      "datadotworld 1.7.0\n",
      "pygsheets 2.0.3.1\n",
      "watermark 2.0.2\n"
     ]
    }
   ],
   "source": [
    "# Import ALL the things\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datadotworld as dw\n",
    "import pygsheets\n",
    "import getpass\n",
    "\n",
    "from io import StringIO\n",
    "from lib.cleaning_tools import *\n",
    "\n",
    "sys.path.append(os.getcwd() + '/../data_cleaning')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Everett Wetchler, Aiden Yang\" -d -t -z -w -p numpy,pandas,datadotworld,pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:50.522506Z",
     "start_time": "2020-11-15T16:28:50.519729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom libraries specific to this project\n",
    "from lib.standardize_police_agency_names import standardize_agency_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 20px\"></div>\n",
    "\n",
    "## 1.b Read data and take a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.186404Z",
     "start_time": "2020-11-15T16:28:50.525923Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = dw.load_dataset(DW_PROJECT_AUXILIARY_DATASETS, force_update=True)\n",
    "agency_county = datasets.dataframes['agencies_and_counties']\n",
    "agency_county = agency_county.set_index('agency')['county'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:29:44.451613Z",
     "start_time": "2020-11-15T16:29:44.439538Z"
    }
   },
   "outputs": [],
   "source": [
    "if getpass.getuser() == 'hlukas':\n",
    "    gc = pygsheets.authorize(service_file='/Users/hlukas/Downloads/client_secret_service.json')\n",
    "else:\n",
    "    gc = pygsheets.authorize(service_file='/home/ec2-user/data-processing/automation/client_secret.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:30:58.179616Z",
     "start_time": "2020-11-15T16:30:58.173646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'create',\n",
       " 'drive',\n",
       " 'get_range',\n",
       " 'logger',\n",
       " 'oauth',\n",
       " 'open',\n",
       " 'open_all',\n",
       " 'open_as_json',\n",
       " 'open_by_key',\n",
       " 'open_by_url',\n",
       " 'sheet',\n",
       " 'spreadsheet_cls',\n",
       " 'spreadsheet_ids',\n",
       " 'spreadsheet_titles',\n",
       " 'teamDriveId']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:37:40.762952Z",
     "start_time": "2020-11-15T16:37:27.602224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 45 raw CDR records. Ignoring 5468 from older form versions (pre-2005).\n",
      "Keeping 5156 records using form version 2005, and 4352 using version 2016 (keeping 9508 in total)\n"
     ]
    }
   ],
   "source": [
    "if getpass.getuser() == 'hlukas':\n",
    "    gc.drive.enable_team_drive('0ACeQWapAwOLqUk9PVA')\n",
    "\n",
    "\n",
    "    titles = gc.spreadsheet_titles()\n",
    "    ids = gc.spreadsheet_ids()\n",
    "\n",
    "    cdr_id = [ids[index] for index in range(len(titles)) if titles[index] == 'CDR Reports All'][0]\n",
    "    output = gc.open_by_key(cdr_id)\n",
    "\n",
    "else:\n",
    "    #gc.enableTeamDriveSupport = True\n",
    "    #gc.teamDriveId = '0ACeQWapAwOLqUk9PVA'\n",
    "    output = gc.open('OIS')\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# drop empty columns or the concatenation does not work\n",
    "for sheet_name in ['Form Version 2005', 'Form Version 2016', 'Older Forms']:\n",
    "    sheet = [i for i in range(4) if output.worksheets()[i].title == sheet_name][0]\n",
    "    wk = output[sheet]\n",
    "    try:\n",
    "        dfs[sheet_name] = wk.get_as_df(include_tailing_empty = True).drop(columns = [''], axis= 1)\n",
    "    except KeyError:\n",
    "        dfs[sheet_name] = wk.get_as_df(include_tailing_empty = True)\n",
    "    \n",
    "dfs['Form Version 2005']['form_version'] = 'V_2005'\n",
    "dfs['Form Version 2016']['form_version'] = 'V_2016'\n",
    "dfs['Older Forms']['form_version'] = 'V_OLDER'\n",
    "\n",
    "cdr = pd.concat([dfs['Form Version 2005'], dfs['Form Version 2016']])\n",
    "print('Read %d raw CDR records. Ignoring %d from older form versions (pre-2005).' % (\n",
    "    sum(len(x) for x in dfs), len(dfs['Older Forms'])))\n",
    "print('Keeping %d records using form version 2005, and %d using version 2016 (keeping %d in total)' % (\n",
    "    len(dfs['Form Version 2005']), len(dfs['Form Version 2016']), len(cdr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:40:34.781098Z",
     "start_time": "2020-11-15T16:40:34.581524Z"
    }
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://www.googleapis.com/drive/v3/files/15othpOTOwB25_ccde4jHK3MaQDAvQyJSXJIVL3eihHg?fields=modifiedTime&alt=json returned \"File not found: 15othpOTOwB25_ccde4jHK3MaQDAvQyJSXJIVL3eihHg.\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-de808ac0eb39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pygsheets/spreadsheet.py\u001b[0m in \u001b[0;36mupdated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m\"\"\"Last time the spreadsheet was modified using RFC 3339 format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_update_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pygsheets/drive.py\u001b[0m in \u001b[0;36mget_update_time\u001b[0;34m(self, file_id)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_update_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m\"\"\"Returns the time this file was last modified in RFC 3339 format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'modifiedTime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'modifiedTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pygsheets/drive.py\u001b[0m in \u001b[0;36m_execute_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://www.googleapis.com/drive/v3/files/15othpOTOwB25_ccde4jHK3MaQDAvQyJSXJIVL3eihHg?fields=modifiedTime&alt=json returned \"File not found: 15othpOTOwB25_ccde4jHK3MaQDAvQyJSXJIVL3eihHg.\">"
     ]
    }
   ],
   "source": [
    "output.updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.241287Z",
     "start_time": "2020-11-15T16:28:50.518Z"
    }
   },
   "outputs": [],
   "source": [
    "# datasets = dw.load_dataset(DW_PROJECT_AUXILIARY_DATASETS, force_update=True)\n",
    "# agency_county = datasets.dataframes['agencies_and_counties']\n",
    "# agency_county = agency_county.set_index('agency')['county'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.243554Z",
     "start_time": "2020-11-15T16:28:50.521Z"
    }
   },
   "outputs": [],
   "source": [
    "# dfs = read_dtw_excel(DW_PROJECT_RAW_AND_PROCESSING, 'original/CDR Reports All.xlsx')\n",
    "# dfs['Form Version 2005']['form_version'] = 'V_2005'\n",
    "# dfs['Form Version 2016']['form_version'] = 'V_2016'\n",
    "# dfs['Older Forms']['form_version'] = 'V_OLDER'\n",
    "# cdr = pd.concat([dfs['Form Version 2005'], dfs['Form Version 2016']])\n",
    "# print('Read %d raw CDR records. Ignoring %d from older form versions (pre-2005).' % (\n",
    "#     sum(len(x) for x in dfs), len(dfs['Older Forms'])))\n",
    "# print('Keeping %d records using form version 2005, and %d using version 2016 (keeping %d in total)' % (\n",
    "#     len(dfs['Form Version 2005']), len(dfs['Form Version 2016']), len(cdr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In theory, all these records should be for deaths in 2005 or later. Let's double check and drop any miscreants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.245983Z",
     "start_time": "2020-11-15T16:28:50.526Z"
    }
   },
   "outputs": [],
   "source": [
    "assert cdr['Death Date and Time'].isnull().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.248194Z",
     "start_time": "2020-11-15T16:28:50.530Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['Death Date and Time'] = pd.to_datetime(cdr['Death Date and Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.250287Z",
     "start_time": "2020-11-15T16:28:50.534Z"
    }
   },
   "outputs": [],
   "source": [
    "before = len(cdr)\n",
    "cdr = cdr[cdr['Death Date and Time'].dt.year >= 2005]\n",
    "after = len(cdr)\n",
    "print('Dropped %d (of %d) reports for deaths before 2005, leaving %d' % (before - after, before, after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.253005Z",
     "start_time": "2020-11-15T16:28:50.537Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Data goes from %s to %s\" % (cdr['Death Date and Time'].min().strftime(\"%Y-%m-%d\"),\n",
    "                                   cdr['Death Date and Time'].max().strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.254690Z",
     "start_time": "2020-11-15T16:28:50.541Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs['Form Version 2005'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.256760Z",
     "start_time": "2020-11-15T16:28:50.545Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs['Form Version 2016'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 20px\"></div>\n",
    "\n",
    "## 1c. Helper methods/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.259054Z",
     "start_time": "2020-11-15T16:28:50.549Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_notnull_chart(cdr, vertical=False):\n",
    "    '''Show which columns have null values, how often, and break down by form version.'''\n",
    "    versions = sorted(set(cdr.form_version))\n",
    "    frames = []\n",
    "    for v in versions:\n",
    "        fr = cdr[cdr.form_version == v]\n",
    "        s = fr.notnull().mean()\n",
    "        frames.append(s)\n",
    "    frame = pd.concat(frames, axis=1)\n",
    "    frame.columns = versions\n",
    "    frame.sort_index(inplace=True)\n",
    "    if not vertical:\n",
    "        frame = frame.T\n",
    "    return frame.style.background_gradient(cmap='RdYlGn', axis=(0 if vertical else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.260983Z",
     "start_time": "2020-11-15T16:28:50.552Z"
    }
   },
   "outputs": [],
   "source": [
    "OTHER_SPECIFY = 'OTHER, SPECIFY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 2. Join disparate datasets, rename and reformat columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 2a. Reduce the number of columns that we keep, and rename them more conveniently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at how often our columns are populated, broken down by form version (since each ask slightly different questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.262513Z",
     "start_time": "2020-11-15T16:28:50.557Z"
    }
   },
   "outputs": [],
   "source": [
    "show_notnull_chart(cdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that we either don't need or haven't written code to clean yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.264651Z",
     "start_time": "2020-11-15T16:28:50.562Z"
    }
   },
   "outputs": [],
   "source": [
    "keep_text = '''Both forms\n",
    "\n",
    "- Age At Time Of Death\n",
    "- Agency Address\n",
    "- Agency City\n",
    "- Agency Name\n",
    "- Agency Zip\n",
    "- CDR: CDR Name\n",
    "- City\n",
    "- County\n",
    "- Date of Birth\n",
    "- Date/Time of Custody or Incident\n",
    "- Death Date and Time\n",
    "- Death Location\n",
    "- Death Location Elsewhere\n",
    "- Entry Date Time\n",
    "- Entry Date Time N/A\n",
    "- First Name\n",
    "- Middle Name\n",
    "- Last Name\n",
    "- Suffix\n",
    "- Manner of Death\n",
    "- Manner of Death Description\n",
    "- Means of Death\n",
    "- Means of Death Other\n",
    "- Medical Cause of Death\n",
    "- Medical Examinor/Coroner Evalution?\n",
    "- Medical Treatment\n",
    "- Offense 1\n",
    "- Offense 2\n",
    "- Offense 3\n",
    "- Pre existing medical condition?\n",
    "- Report Date\n",
    "- Sex\n",
    "- Specific Type of Custody/Facility\n",
    "- Street Address\n",
    "- Type of Custody\n",
    "- Type of Offense\n",
    "- Type of Offense, Other\n",
    "- Version Number\n",
    "- Version Type\n",
    "- Were the Charges:\n",
    "- Who caused the death?\n",
    "- form_version\n",
    "- Type of Restraint\n",
    "- Under Restraint\n",
    "\n",
    "2005 form only\n",
    "\n",
    "- Agency County\n",
    "- Custody Date NA\n",
    "- Death Causer Other\n",
    "- Department Type\n",
    "- Entry Behavior\n",
    "- Ethnicity\n",
    "- Ethnicity Other\n",
    "- Other Behavior\n",
    "- Specify Other Behavior\n",
    "\n",
    "2016 form only\n",
    "\n",
    "- Exhibit any medical problems?\n",
    "- Exhibit any mental health problems?\n",
    "- Make suicidal statements?\n",
    "- Race'''\n",
    "keep_cols = []\n",
    "drop_cols = set(cdr.columns)\n",
    "for line in keep_text.splitlines():\n",
    "    if line.startswith('- '):\n",
    "        colname = line[2:]\n",
    "        keep_cols.append(colname)\n",
    "        drop_cols.remove(colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns to be more machine friendly (lowercase, snake_case, and remove non-alphanumeric characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.266919Z",
     "start_time": "2020-11-15T16:28:50.566Z"
    }
   },
   "outputs": [],
   "source": [
    "col_renames = {}\n",
    "for c in keep_cols:\n",
    "    new_name = ''.join([ch if ch.isalnum() else ' ' for ch in c.lower()])\n",
    "    new_name = '_'.join(new_name.strip().split())\n",
    "    col_renames[c] = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.268604Z",
     "start_time": "2020-11-15T16:28:50.569Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr = cdr[list(col_renames.keys())]\n",
    "cdr.rename(columns=col_renames, inplace=True)\n",
    "cdr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 2b. Add rows from the old master file to get BJS inpatient deaths (will dedup later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.270181Z",
     "start_time": "2020-11-15T16:28:50.573Z"
    }
   },
   "outputs": [],
   "source": [
    "# gc.drive.enable_team_drive('0ACeQWapAwOLqUk9PVA')\n",
    "# titles = gc.spreadsheet_titles()\n",
    "# ids = gc.spreadsheet_ids()\n",
    "\n",
    "# cdr_id = [ids[index] for index in range(len(titles)) if titles[index] == 'reformatted_cdr_2017_master_file'][0]\n",
    "# output = gc.open_by_key(cdr_id)\n",
    "\n",
    "# wk = output[0]\n",
    "\n",
    "# dfs = {}\n",
    "\n",
    "# # drop empty columns or the concatenation does not work\n",
    "# for sheet_name in ['Form Version 2005', 'Form Version 2016', 'Older Forms']:\n",
    "#     sheet = [i for i in range(4) if output.worksheets()[i].title == sheet_name][0]\n",
    "#     wk = output[sheet]\n",
    "#     try:\n",
    "#         dfs[sheet_name] = wk.get_as_df(include_tailing_empty = True).drop(columns = [''], axis= 1)\n",
    "#     except KeyError:\n",
    "#         dfs[sheet_name] = wk.get_as_df(include_tailing_empty = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.271985Z",
     "start_time": "2020-11-15T16:28:50.576Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = dw.load_dataset(DW_PROJECT_RAW_AND_PROCESSING, force_update=True)\n",
    "old_master = datasets.dataframes['reformatted_cdr_2017_master_file']\n",
    "old_master['form_version'] = 'V_BJS'\n",
    "print(old_master.shape)\n",
    "old_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.273445Z",
     "start_time": "2020-11-15T16:28:50.579Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.shape, old_master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There will be a few columns that the old master file doesn't have, which is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.275355Z",
     "start_time": "2020-11-15T16:28:50.583Z"
    }
   },
   "outputs": [],
   "source": [
    "set(cdr.columns) - set(old_master.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, it shouldn't have any novel columns that the *other* data doesn't have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.277985Z",
     "start_time": "2020-11-15T16:28:50.587Z"
    }
   },
   "outputs": [],
   "source": [
    "assert(len(set(old_master.columns) - set(cdr.columns)) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the \"old master\" file with the other CDR records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.280562Z",
     "start_time": "2020-11-15T16:28:50.591Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr = pd.concat([cdr, old_master])\n",
    "cdr.reset_index(inplace=True, drop=True)\n",
    "cdr.sort_values('form_version', inplace=True)\n",
    "cdr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 2c. Data is merged into one frame. Now do column type conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.282921Z",
     "start_time": "2020-11-15T16:28:50.597Z"
    }
   },
   "outputs": [],
   "source": [
    "s1 = cdr.dtypes\n",
    "convert_date_cols(cdr)\n",
    "s2 = cdr.dtypes\n",
    "different = s1[s1 != s2].index.tolist()\n",
    "print(\"Changed %d cols to datetime (from some other dtype):\" % len(different), different)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As shown below, some float columns are in string format. We'll fix that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.284974Z",
     "start_time": "2020-11-15T16:28:50.601Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.entry_date_time_n_a.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.286406Z",
     "start_time": "2020-11-15T16:28:50.604Z"
    }
   },
   "outputs": [],
   "source": [
    "def float_or_nan(val):\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except TypeError:\n",
    "        pass\n",
    "    print(\"- BAD VALUE (returning NaN):\", val)\n",
    "    return np.NAN\n",
    "\n",
    "float_cols = [\n",
    " 'age_at_time_of_death',\n",
    " 'agency_zip',\n",
    " 'custody_date_na',\n",
    " 'entry_date_time_n_a',\n",
    " 'version_number'\n",
    "]\n",
    "\n",
    "for c in float_cols:\n",
    "    print(\"Converting\", c)\n",
    "    cdr[c] = cdr[c].apply(float_or_nan).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcase string cell contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.288024Z",
     "start_time": "2020-11-15T16:28:50.608Z"
    }
   },
   "outputs": [],
   "source": [
    "upcase_strip_string_cells(cdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a `death_date` column (without the death time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.289877Z",
     "start_time": "2020-11-15T16:28:50.612Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['death_date'] = pd.to_datetime(cdr.death_date_and_time.apply(lambda dt: datetime.date(dt.year, dt.month, dt.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.291974Z",
     "start_time": "2020-11-15T16:28:50.615Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr_ready_to_clean = cdr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 3. Begin deep cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.295252Z",
     "start_time": "2020-11-15T16:28:50.619Z"
    }
   },
   "outputs": [],
   "source": [
    "# When we're working on modifying this file, and we need to reset\n",
    "# the dataset, it's annoying to run the whole notebook, fetch from\n",
    "# data.world, etc. So you can just rerun from here downward.\n",
    "cdr = cdr_ready_to_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 3a.  Standardize `race` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to merge race and ethnicity columns (the 2005 form calls it 'ethnicity', the 2016 'race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a look at the values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.297335Z",
     "start_time": "2020-11-15T16:28:50.624Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.299090Z",
     "start_time": "2020-11-15T16:28:50.628Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.300490Z",
     "start_time": "2020-11-15T16:28:50.631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collapse the various OTHER-like values\n",
    "cdr.loc[cdr.ethnicity.fillna('').str.contains('OTHER'), 'ethnicity'] = 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.301985Z",
     "start_time": "2020-11-15T16:28:50.634Z"
    }
   },
   "outputs": [],
   "source": [
    "# When choosing the 'Other' ethnicity in the 2005 form version, there\n",
    "# is a subsequent field to specify. Though clearly some of them are not\n",
    "# truly 'other' ethnicities. See:\n",
    "cdr.ethnicity_other.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.303477Z",
     "start_time": "2020-11-15T16:28:50.637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the nonsensical 0 with NaN\n",
    "cdr.loc[cdr.ethnicity_other.astype(str) == '0', 'ethnicity_other'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.305456Z",
     "start_time": "2020-11-15T16:28:50.640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's make sure nobody is filling out the \"other ethnicity\" column when they shouldn't...\n",
    "cdr[(~(cdr.ethnicity == 'OTHER') & cdr.ethnicity_other.notnull())][['ethnicity', 'ethnicity_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.306837Z",
     "start_time": "2020-11-15T16:28:50.644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Good. Let's transfer those specified ethnicity_other values into\n",
    "# the 'ethnicity' column, so we can merge everything at once.\n",
    "other_eth = (cdr.ethnicity == 'OTHER')\n",
    "print('Merging %d \"ethnicity_other\" values into the main \"ethnicity\" column' % other_eth.sum())\n",
    "cdr.loc[other_eth, 'ethnicity'] = cdr.ethnicity_other[other_eth]\n",
    "cdr.drop('ethnicity_other', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.308429Z",
     "start_time": "2020-11-15T16:28:50.648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a single 'race' column that has merged, simplified values of race or ethnicity.\n",
    "race_eth_list = []\n",
    "for race, eth in zip(cdr.race, cdr.ethnicity):\n",
    "    # Only one of (race, eth) should be set\n",
    "    assert pd.isnull(race) or pd.isnull(eth)\n",
    "    if pd.isnull(race):\n",
    "        if pd.isnull(eth):\n",
    "            race_eth_list.append(None)\n",
    "            continue\n",
    "        x = eth\n",
    "    else:\n",
    "        x = race\n",
    "    race_eth_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.311200Z",
     "start_time": "2020-11-15T16:28:50.651Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['race'] = race_eth_list\n",
    "cdr.drop('ethnicity', axis=1, inplace=True)\n",
    "cdr.race.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Collapse `race` values into a smaller set (white/hispanic/black/other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.314103Z",
     "start_time": "2020-11-15T16:28:50.655Z"
    }
   },
   "outputs": [],
   "source": [
    "race_before = cdr.race.copy()\n",
    "race_before.name = 'race_before'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.316207Z",
     "start_time": "2020-11-15T16:28:50.657Z"
    }
   },
   "outputs": [],
   "source": [
    "standardize_race_cols(cdr)\n",
    "cdr.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.318721Z",
     "start_time": "2020-11-15T16:28:50.661Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.groupby([race_before, 'race']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 3b. Standardize agency information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.320814Z",
     "start_time": "2020-11-15T16:28:50.665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize agency name (so we can join/compare across datasets)\n",
    "cdr['agency_name'] = cdr['agency_name'].apply(standardize_agency_name)\n",
    "\n",
    "# Lookup county name by agency name. If this fails, fall back\n",
    "# on the county specified in the form, if it exists.\n",
    "cdr['agency_county'] = cdr['agency_county'].str.upper()\n",
    "county_lookup = cdr['agency_name'].apply(lambda name: agency_county.get(name, np.nan))\n",
    "cdr['agency_county'] = county_lookup.fillna(cdr['agency_county'])\n",
    "\n",
    "# Manually handle one major agency\n",
    "cdr.loc[cdr['agency_name'] == 'TEXAS DEPT OF CRIMINAL JUSTICE', 'agency_county'] = 'STATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.322594Z",
     "start_time": "2020-11-15T16:28:50.669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check that we are only missing counties for a paltry few records now.\n",
    "cdr[cdr['agency_county'].isnull()]['agency_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.324423Z",
     "start_time": "2020-11-15T16:28:50.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clearly 'TEST CDR AGENCY' is meant to be ignored\n",
    "test_agencies = cdr['agency_name'] == 'TEST CDR AGENCY'\n",
    "cdr = cdr[~test_agencies]\n",
    "print(\"Dropping %d records from 'TEST CDR AGENCY', leaving %d records\" % (test_agencies.sum(), len(cdr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 3c.  Fix death-information related columns\n",
    "\n",
    "#### The two form versions offer slightly different options (e.g. V_2005 uses 'AT MEDICAL FACILITY' while V_2016 uses 'MEDICAL FACILITY'). Collapse values to stabilize the options across form versions, and roll up rare values into a single 'OTHER' value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `death_location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.326378Z",
     "start_time": "2020-11-15T16:28:50.677Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.death_location, cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.328521Z",
     "start_time": "2020-11-15T16:28:50.680Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'AT MEDICAL FACILITY': 'MEDICAL FACILITY',\n",
    "    'AT LAW ENFORCEMENT FACILITY': 'LAW ENFORCEMENT FACILITY',\n",
    "    'AT THE CRIME/ARREST SCENE': 'CRIME/ARREST SCENE',\n",
    "    'SCENE OF INCIDENT': 'CRIME/ARREST SCENE',\n",
    "    'LAW ENFORCEMENT FACILITY/BOOKING CENTER': 'LAW ENFORCEMENT FACILITY',\n",
    "    'DEAD ON ARRIVAL AT MEDICAL FACILITY': 'EN ROUTE TO MEDICAL FACILITY',\n",
    "    'EN ROUTE TO BOOKING CENTER/POLICE LOCKUP': 'EN ROUTE TO LAW ENFORCEMENT FACILITY',\n",
    "    'ELSEWHERE': OTHER_SPECIFY,\n",
    "    'ELSEWHERE, SPECIFY': OTHER_SPECIFY,\n",
    "}\n",
    "cdr['death_location'] = cdr['death_location'].apply(lambda x: None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr.death_location, cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `means_of_death`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.330282Z",
     "start_time": "2020-11-15T16:28:50.684Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.means_of_death, cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.332046Z",
     "start_time": "2020-11-15T16:28:50.687Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'NOT APPLICABLE, CAUSE OF DEATH WAS ILLNESS/NATURAL CAUSE': 'NOT APPLICABLE',\n",
    "    'NOT APPLICABLE; CAUSE OF DEATH WAS INTOXICATION OR ILLNESS/NATURAL CAUSES': 'NOT APPLICABLE',\n",
    "    'OTHER': OTHER_SPECIFY,\n",
    "    'KNIFE, CUTTING INSTRUMENT': 'KNIFE / EDGED INSTRUMENT',\n",
    "    'BLUNT INSTRUMENT': 'BATON / BLUNT INSTRUMENT',\n",
    "    \"DON'T KNOW\": 'UNKNOWN',\n",
    "    \"DON\\\\'T KNOW\": 'UNKNOWN',\n",
    "    'RIFLE/SHOTGUN': 'FIREARM',\n",
    "}\n",
    "cdr['means_of_death'] = cdr['means_of_death'].apply(lambda x:  None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr.means_of_death, cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems officers sometimes misuse the 'other' option, selecting it when another category is more appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.334409Z",
     "start_time": "2020-11-15T16:28:50.692Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr[cdr.means_of_death == OTHER_SPECIFY]['means_of_death_other'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's roll all rare and 'unknown'-type values into the 'other' category. 'VEHICLE ACCIDENT' in particular is new in the 2016 form, only indicated as 'other' in older forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.336050Z",
     "start_time": "2020-11-15T16:28:50.696Z"
    }
   },
   "outputs": [],
   "source": [
    "other_values = ['UNKNOWN', 'VEHICLE ACCIDENT', 'KNIFE / EDGED INSTRUMENT', 'BATON / BLUNT INSTRUMENT']\n",
    "indices = cdr['means_of_death'].isin(other_values)\n",
    "cdr.loc[indices, 'means_of_death_other'] = cdr.loc[indices, 'means_of_death']\n",
    "cdr.loc[indices, 'means_of_death'] = OTHER_SPECIFY\n",
    "\n",
    "pd.crosstab(cdr.means_of_death, cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `manner_of_death` and  `manner_of_death_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.337915Z",
     "start_time": "2020-11-15T16:28:50.700Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.form_version, cdr.manner_of_death).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.339533Z",
     "start_time": "2020-11-15T16:28:50.703Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.manner_of_death, cdr.manner_of_death_description.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.341085Z",
     "start_time": "2020-11-15T16:28:50.706Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'NATURAL': 'NATURAL CAUSES/ILLNESS',\n",
    "    'JUSTIFIABLE HOMICIDE': 'HOMICIDE',\n",
    "    'HOMICIDE BY LAW ENFORCEMENT/CORRECTIONAL STAFF': 'HOMICIDE',\n",
    "    'OTHER HOMICIDE': 'HOMICIDE',\n",
    "    'HOMICIDE (INCLUDES JUSTIFIABLE HOMICIDE)': 'HOMICIDE',\n",
    "    'ACCIDENTAL INJURY CAUSED BY OTHERS': 'ACCIDENTAL',\n",
    "    'ACCIDENTAL INJURY TO SELF': 'ACCIDENTAL',\n",
    "    'OTHER': OTHER_SPECIFY,\n",
    "    'OTHER - SPECIFY': OTHER_SPECIFY,\n",
    "}\n",
    "cdr['manner_of_death'] = cdr['manner_of_death'].apply(lambda x: None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "\n",
    "# In past versions, \"pending autopsy results\" was not an option, and reports had \"other\"\n",
    "# checked with some mention of pending autopsy in the free field. We emulate this here\n",
    "# to preserve consistency across form versions.\n",
    "other_values = ['PENDING AUTOPSY RESULTS', 'COULD NOT BE DETERMINED']\n",
    "indices = cdr['manner_of_death'].isin(other_values)\n",
    "cdr.loc[indices, 'manner_of_death_description'] = cdr.loc[indices, 'manner_of_death']\n",
    "cdr.loc[indices, 'manner_of_death'] = OTHER_SPECIFY\n",
    "\n",
    "pd.crosstab(cdr.form_version, cdr.manner_of_death).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few suicides by hanging have the wrong `means_of_death`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.342991Z",
     "start_time": "2020-11-15T16:28:50.710Z"
    }
   },
   "outputs": [],
   "source": [
    "frame = cdr[(cdr.manner_of_death == 'SUICIDE') & (cdr.means_of_death != 'HANGING, STRANGULATION')]\n",
    "frame = frame[(frame.medical_cause_of_death.fillna('').str.contains('HANGING')) |\n",
    "              frame.manner_of_death_description.fillna('').str.contains('HANGING')]\n",
    "print(len(frame))\n",
    "frame[['medical_cause_of_death', 'means_of_death', 'means_of_death_other', 'manner_of_death', 'manner_of_death_description']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.344847Z",
     "start_time": "2020-11-15T16:28:50.713Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.loc[frame.index, 'means_of_death'] = 'HANGING, STRANGULATION'\n",
    "\n",
    "# Be sure we got them all\n",
    "frame = cdr[(cdr.manner_of_death == 'SUICIDE') & (cdr.means_of_death != 'HANGING, STRANGULATION')]\n",
    "frame = frame[frame.medical_cause_of_death.fillna('').str.contains('HANGING')]\n",
    "assert len(frame) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a few suicides, the `manner_of_death` is 'NOT APPLICABLE', which makes no sense. We need to change these to OTHER, though (as shown below) more is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.346369Z",
     "start_time": "2020-11-15T16:28:50.717Z"
    }
   },
   "outputs": [],
   "source": [
    "frame = cdr[(cdr.manner_of_death == 'SUICIDE') & (cdr.means_of_death == 'NOT APPLICABLE')]\n",
    "print(len(frame))\n",
    "frame[['means_of_death', 'means_of_death_other', 'manner_of_death', 'manner_of_death_description', 'medical_cause_of_death']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.347771Z",
     "start_time": "2020-11-15T16:28:50.720Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.loc[frame.index, 'means_of_death'] = OTHER_SPECIFY\n",
    "assert len(cdr[(cdr.manner_of_death == 'SUICIDE') & (cdr.means_of_death == 'NOT APPLICABLE')]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `pre_existing_medical_condition` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.349220Z",
     "start_time": "2020-11-15T16:28:50.724Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.form_version, cdr.pre_existing_medical_condition).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.350596Z",
     "start_time": "2020-11-15T16:28:50.728Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'DECEASED DEVELOPED CONDITION AFTER ADMISSION': 'DEVELOPED CONDITION AFTER ADMISSION',\n",
    "    \"DON'T KNOW\": 'UNKNOWN',\n",
    "    \"DON\\\\'T KNOW\": 'UNKNOWN',\n",
    "    'NOT APPLICABLE; CAUSE OF DEATH WAS ACCIDENTAL INJURY, INTOXICATION, SUICIDE OR HOMICIDE': 'NOT APPLICABLE',\n",
    "    'COULD NOT BE DETERMINED': 'UNKNOWN',\n",
    "    'PRE-EXISTING MEDICAL CONDITION': 'YES',\n",
    "}\n",
    "cdr['pre_existing_medical_condition'] = cdr['pre_existing_medical_condition'].apply(lambda x: None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr.form_version, cdr.pre_existing_medical_condition).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `who_caused_the_death` \n",
    "\n",
    "NOTE: This question is framed as follows:\n",
    "* 2005 form: \"If the death was an accident or homicide, who caused the death?\"\n",
    "* 2016 form: \"If the death was an accident, homicide **or suicide**, who caused the death?\" (emphasis added)\n",
    "\n",
    "Thus, we need to:\n",
    "1. Collapse near-identical values from different forms, similar to the other areas here.\n",
    "1. Remove suicides from the 2016 responses, as they skew the data (see below). While we're add it, change ANY entries that are not of type homicide/suicide to have \"NOT APPLICABLE\" as the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapse near-identical values from different forms, similar to the other areas here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.352478Z",
     "start_time": "2020-11-15T16:28:50.733Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.who_caused_the_death, cdr.death_date_and_time.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.353870Z",
     "start_time": "2020-11-15T16:28:50.736Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'DECEASED': 'DECEDENT',\n",
    "    \"DON'T KNOW\": 'UNKNOWN',\n",
    "    \"DON\\\\'T KNOW\": 'UNKNOWN',\n",
    "    'LAW ENFORCEMENT/CORRECTIONAL STAFF': 'LAW ENFORCEMENT/CORRECTIONAL PERSONNEL',\n",
    "    'NOT APPLICABLE; CAUSE OF DEATH WAS SUICIDE, INTOXICATION OR ILLNESS/NATURAL CAUSES': 'NOT APPLICABLE',\n",
    "    'OTHER DETAINEES': 'OTHER DETAINEE(S)',\n",
    "    'OTHER PERSONS': 'OTHER CIVILIAN(S)',\n",
    "    'ACCIDENTAL INJURY TO SELF': 'ACCIDENTAL',\n",
    "    'UNKNOWN PERSON(S) CAUSED THE INJURY': 'UNKNOWN',\n",
    "    'UNKNOWN WHETHER DECEDENT SUSTAINED A FATAL INJURY': 'UNKNOWN',\n",
    "}\n",
    "cdr['who_caused_the_death'] = cdr['who_caused_the_death'].apply(lambda x:  None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr['who_caused_the_death'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove suicides from the 2016 responses to 'who caused the death' question, as in previous years 'who caused the death' was only asked for homicides and accidents. (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.355243Z",
     "start_time": "2020-11-15T16:28:50.739Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.who_caused_the_death, cdr.manner_of_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.356696Z",
     "start_time": "2020-11-15T16:28:50.742Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.loc[~cdr.manner_of_death.isin(['HOMICIDE', 'ACCIDENTAL', OTHER_SPECIFY]), 'who_caused_the_death'] = 'NOT APPLICABLE'\n",
    "pd.crosstab(cdr.who_caused_the_death, cdr.manner_of_death)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `medical_examinor_coroner_evalution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.358424Z",
     "start_time": "2020-11-15T16:28:50.745Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.form_version, cdr.medical_examinor_coroner_evalution).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.359829Z",
     "start_time": "2020-11-15T16:28:50.748Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_coroner(result):\n",
    "    if pd.isnull(result):\n",
    "        return None\n",
    "    result = result.strip()\n",
    "    if result.startswith('YES'):\n",
    "        return 'YES'\n",
    "    elif result.startswith('NO'):\n",
    "        return 'NO'\n",
    "    return None\n",
    "\n",
    "cdr['medical_examinor_coroner_evalution'] = cdr['medical_examinor_coroner_evalution'].apply(fix_coroner)\n",
    "pd.crosstab(cdr.form_version, cdr.medical_examinor_coroner_evalution).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 3d.  Fix other columns one-by-one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `gender` related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.361533Z",
     "start_time": "2020-11-15T16:28:50.752Z"
    }
   },
   "outputs": [],
   "source": [
    "standardize_gender_cols(cdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix: `were_the_charges` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.363073Z",
     "start_time": "2020-11-15T16:28:50.756Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr['were_the_charges'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.364423Z",
     "start_time": "2020-11-15T16:28:50.759Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'CAPITAL MURDER': 'CONVICTED',\n",
    "    'PROBATION/PAROLE': 'PROBATION/PAROLE VIOLATION',\n",
    "    'A PROBATION/PAROLE VIOLATION': 'PROBATION/PAROLE VIOLATION',\n",
    "}\n",
    "cdr['were_the_charges'] = cdr['were_the_charges'].apply(lambda x: None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr['were_the_charges'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `type_of_custody`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.365927Z",
     "start_time": "2020-11-15T16:28:50.762Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr['type_of_custody'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.367532Z",
     "start_time": "2020-11-15T16:28:50.765Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'PRE-CUSTODIAL USE OF FORCE': 'POLICE CUSTODY (PRE-BOOKING)',\n",
    "    'PRIVATE CORRECTIONAL FACILITY': 'PRIVATE FACILITY',\n",
    "    'COUNTY JAIL': 'JAIL - COUNTY',\n",
    "    'MUNICIPAL JAIL': 'JAIL - MUNICIPAL',\n",
    "    'PENITENTIARY': 'PRISON',\n",
    "}\n",
    "cdr['type_of_custody'] = cdr['type_of_custody'].apply(lambda x: None if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr['type_of_custody'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `specific_type_of_custody_facility`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.369138Z",
     "start_time": "2020-11-15T16:28:50.768Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.specific_type_of_custody_facility, cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.370750Z",
     "start_time": "2020-11-15T16:28:50.771Z"
    }
   },
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'TDCJ, SPECIFY': 'TDCJ',\n",
    "    'CUSTODY OF PEACE OFFICER DURING/FLEEING ARREST': 'CUSTODY OF LAW ENFORCEMENT PERSONNEL DURING/FLEEING ARREST',\n",
    "    'CUSTODY OF PEACE OFFICER SUBSEQUENT TO ARREST': 'CUSTODY OF LAW ENFORCEMENT PERSONNEL AFTER ARREST',\n",
    "    'CUSTODY OF LAW ENFORCEMENT PERSONNEL SUBSEQUENT TO ARREST': 'CUSTODY OF LAW ENFORCEMENT PERSONNEL AFTER ARREST',\n",
    "    'TEXAS-JUVENILE JUSTICE DEPARTMENT - FACILITY/DETENTION CENTER, SPECIFY': 'OTHER',\n",
    "    'TJPC': 'OTHER',\n",
    "    'TYC': 'OTHER',\n",
    "    'HALFWAY HOUSE/RESTITUTION CENTER': 'OTHER',\n",
    "    'CORRECTIONAL/REHABILITATION FACILITY': 'OTHER',\n",
    "    'NON-LAW ENFORCEMENT DETOX FACILITY': 'OTHER',\n",
    "}\n",
    "cdr['specific_type_of_custody_facility'] = cdr['specific_type_of_custody_facility'].apply(\n",
    "    lambda x: x if pd.isnull(x) else replacements.get(x.strip(), x))\n",
    "pd.crosstab(cdr['specific_type_of_custody_facility'], cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance at the types of custody crossed with facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.372047Z",
     "start_time": "2020-11-15T16:28:50.774Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.specific_type_of_custody_facility, cdr.type_of_custody)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `other_behavior` and `specify_other_behavior` are very annoying and misused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.373637Z",
     "start_time": "2020-11-15T16:28:50.778Z"
    }
   },
   "outputs": [],
   "source": [
    "s = cdr['other_behavior'].value_counts()\n",
    "print(\"%d records have 'other_behavior' set (%d do not)\" % (s.sum(), len(cdr) - s.sum()))\n",
    "print(\"%d unique values for 'other_behavior' - sample below:\" % len(set(s)))\n",
    "s.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.375110Z",
     "start_time": "2020-11-15T16:28:50.781Z"
    }
   },
   "outputs": [],
   "source": [
    "s = cdr['specify_other_behavior'].value_counts()\n",
    "print(\"%d records have 'specify_other_behavior' set (%d do not)\" % (s.sum(), len(cdr) - s.sum()))\n",
    "print(\"%d unique values for 'specify_other_behavior' - sample below:\" % len(set(s)))\n",
    "s.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It _appears_ that anytime other_behavior is 1.0, specify_other_behavior is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.376914Z",
     "start_time": "2020-11-15T16:28:50.784Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr[cdr['specify_other_behavior'].notnull()]['other_behavior'].fillna('(None)').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright, we can just overwrite 'other_behavior' with 'specify_other_behavior' when the latter is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.378656Z",
     "start_time": "2020-11-15T16:28:50.788Z"
    }
   },
   "outputs": [],
   "source": [
    "behavior = []\n",
    "for other, specify in zip(cdr['other_behavior'], cdr['specify_other_behavior']):\n",
    "    if pd.notnull(specify):\n",
    "        behavior.append(specify)\n",
    "    else:\n",
    "        try:\n",
    "            other = float(other)\n",
    "            if other == 0.0:\n",
    "                behavior.append(None)\n",
    "                continue\n",
    "        except TypeError:\n",
    "            pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        behavior.append(other)\n",
    "\n",
    "cdr['other_behavior'] = pd.Series(behavior, index=cdr.index)\n",
    "cdr.drop('specify_other_behavior', axis=1, inplace=True)\n",
    "\n",
    "cdr['other_behavior'].fillna('(None)').value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 3e. Identify and drop a range of unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `entry_date_time_n_a` and `custody_date_na` are useless - we can infer them from (duh) an NA value in entry_date_time or custody_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.379967Z",
     "start_time": "2020-11-15T16:28:50.792Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.groupby([cdr.entry_date_time.isnull(), cdr.entry_date_time_n_a]).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.381552Z",
     "start_time": "2020-11-15T16:28:50.795Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.custody_date_na, cdr['date_time_of_custody_or_incident'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.382911Z",
     "start_time": "2020-11-15T16:28:50.798Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.drop(['entry_date_time_n_a', 'custody_date_na'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'department_type' is not consistently present. Drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.384633Z",
     "start_time": "2020-11-15T16:28:50.801Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.department_type.notnull(), cdr.form_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.386570Z",
     "start_time": "2020-11-15T16:28:50.804Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.drop('department_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 4. De-duplicate (oh boy, this is a doozy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In theory we should able to de-dup by the record id (`cdr_cdr_name`), BUT...\n",
    "1. Sometimes two records with the same record ID differ on some columns. _Usually_ the version_number can tell us which one is the latest, but not always.\n",
    "1. Sometimes we'll see multiple records for the same person with different record IDs (ugh).\n",
    "\n",
    "...so it's complicated.\n",
    "\n",
    "### After a LOT of tinkering, I think we can catch most reasonable duplicates with the following:\n",
    "  * Drop all records that are a complete, exact duplicate of another (easy step)\n",
    "  * Merge all records sharing a record id, `cdr_cdr_name`\n",
    "  * Merge all records with the same name and date of birth\n",
    "  * Merge all records with the same name and date of death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Get rid of totally, utterly duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.388008Z",
     "start_time": "2020-11-15T16:28:50.809Z"
    }
   },
   "outputs": [],
   "source": [
    "pure_dups = cdr.duplicated()\n",
    "cdr = cdr[~pure_dups]\n",
    "print(\"Dropping %d rows that are 100%% duplicates of another row, leaving %d rows\" % (pure_dups.sum(), len(cdr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Define some dedup functions to help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.389812Z",
     "start_time": "2020-11-15T16:28:50.813Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_dup_records(frame):\n",
    "    '''Master merge function. Creates one record from several that are known duplicates.'''\n",
    "    # Ignore BJS records (these are from and old data dump),\n",
    "    # unless there is no other option.\n",
    "    form_versions_seen = set(frame['form_version'])\n",
    "    if 'V_BJS' in form_versions_seen and len(form_versions_seen) > 1:\n",
    "        frame = frame[frame['form_version'] != 'V_BJS']\n",
    "        if len(frame) == 1:\n",
    "            return frame.iloc[0], 'Keeping the only non-BJS record'\n",
    "    \n",
    "    \n",
    "    # If one record has a higher version_number than the rest, keep that one.\n",
    "    # If one record has a more recent report_date than the rest, keep that one.\n",
    "    max_cols = ['version_number', 'report_date']\n",
    "    for c in max_cols:\n",
    "        maxval = frame[c].max()  # Implicitly ignores missing values, unless only missing values exist\n",
    "        if pd.notnull(maxval):\n",
    "            frame = frame[frame[c] == maxval]\n",
    "            if len(frame) == 1:\n",
    "                return frame.iloc[0], 'Keeping the record with greatest %s' % c\n",
    "\n",
    "    # Otherwise, there's no way to flag the \"one\" right record (that I know of).\n",
    "    # So we gotta merge them somehow...\n",
    "    merged_rec = pd.Series(index = frame.columns,\n",
    "                           name = 1000000 + frame.index[0])  # Give it a new, unique index\n",
    "    awk = False\n",
    "    for c in frame.columns:\n",
    "        notnull = frame[c][frame[c].notnull()]\n",
    "\n",
    "        # If all records have NA for this column, leave it as NA\n",
    "        if len(notnull) == 0:\n",
    "            merged_rec[c] = frame[c].iloc[0]\n",
    "            continue\n",
    "\n",
    "        # Only 1 unique not-null value? Keep that one.\n",
    "        if len(notnull) == 1 or len(set(notnull)) == 1:\n",
    "            merged_rec[c] = notnull.iloc[0]\n",
    "            continue\n",
    "        \n",
    "        # Are we trying to merge record IDs? That's impossible anyway,\n",
    "        # let's just concatenate them.\n",
    "        if c == 'cdr_cdr_name':\n",
    "            merged_rec[c] = '-'.join(notnull)\n",
    "            continue\n",
    "        \n",
    "        # Well, poop. Multiple unique values for this column.\n",
    "        # Take the most popular one \\_()_/\n",
    "        # (Which will just be a random one if there's a tie \\_()_/ )\n",
    "        awk = True\n",
    "        vc = notnull.value_counts()\n",
    "        keeper = vc.index[0]\n",
    "        if vc.iloc[0] > vc.iloc[1]:\n",
    "            print(\"  > Problem with column %s, keeping the most popular value, '%s'\"\n",
    "                  % (c, keeper), notnull.values)\n",
    "        else:\n",
    "            print(\"  > Problem with column %s, keeping an arbitrary tied-for-most-popular value, '%s'\"\n",
    "                  % (c, keeper), notnull.values)\n",
    "        merged_rec[c] = keeper\n",
    "\n",
    "    merged_rec['cdr_cdr_name'] = 'MERGED-DUPLICATES-%s' % merged_rec['cdr_cdr_name']\n",
    "    if awk:\n",
    "        return merged_rec, 'Merged awkwardly'\n",
    "    else:\n",
    "        return merged_rec, 'Merged smoothly enough'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.392812Z",
     "start_time": "2020-11-15T16:28:50.815Z"
    }
   },
   "outputs": [],
   "source": [
    "def dedup_cdr_by(cdr, cols):\n",
    "    '''Given a cdr dataframe, and a set of columns to use to identify duplicates, dedups/merges as needed.'''\n",
    "    dups = cdr[cdr.duplicated(subset=cols, keep=False)]\n",
    "    if not len(dups):\n",
    "        return cdr\n",
    "    unmerged_frames = []\n",
    "    merged_records = []\n",
    "    merge_methods = []\n",
    "    for _, frame in dups.groupby(cols):\n",
    "        rec, meth = merge_dup_records(frame)\n",
    "        unmerged_frames.append(frame)\n",
    "        merged_records.append(rec)\n",
    "        merge_methods.append(meth)\n",
    "        if 'awkward' in meth:\n",
    "            print(\"...awkward merge complete for records at indices\", frame.index)\n",
    "\n",
    "    return cdr.drop(dups.index).append(merged_records), unmerged_frames, merged_records, merge_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Dedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.395087Z",
     "start_time": "2020-11-15T16:28:50.819Z"
    }
   },
   "outputs": [],
   "source": [
    "dedup_rounds = [\n",
    "    ['cdr_cdr_name'],\n",
    "    ['first_name', 'last_name', 'date_of_birth'],\n",
    "    ['first_name', 'last_name', 'death_date'],\n",
    "]\n",
    "all_cdrs = [cdr]\n",
    "all_merged_records = []\n",
    "all_unmerged_frames = []\n",
    "all_merge_methods = []\n",
    "for i, dr in enumerate(dedup_rounds):\n",
    "    print('**** Dedup step %d: find duplicates on these columns:' % (i + 1), dr)\n",
    "    vals = dedup_cdr_by(all_cdrs[-1], dr)\n",
    "    new_cdr, umf, mr, mm = vals\n",
    "    all_cdrs.append(new_cdr)\n",
    "    all_unmerged_frames.append(umf)\n",
    "    all_merged_records.append(mr)\n",
    "    all_merge_methods.append(mm)\n",
    "    dropping = sum(len(f) for f in umf)\n",
    "    print(\"Dropping %d duplicates and adding %d merged records, yielding %d records\" % (\n",
    "        dropping, len(mr), len(new_cdr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.397021Z",
     "start_time": "2020-11-15T16:28:50.822Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Ultimately removing %d duplicate records, leaving %d\" % (\n",
    "    len(all_cdrs[0]) - len(all_cdrs[-1]), len(all_cdrs[-1])))\n",
    "cdr = all_cdrs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. If you want to inspect the merges (what records were merged into what), use the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.398831Z",
     "start_time": "2020-11-15T16:28:50.825Z"
    }
   },
   "outputs": [],
   "source": [
    "for rd, cols in enumerate(dedup_rounds):\n",
    "    print(\"In round %d, there were %d record merges based on\" % (rd, len(all_merged_records[rd])), cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.400535Z",
     "start_time": "2020-11-15T16:28:50.828Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_merge(merge_round, idx):\n",
    "    umf = all_unmerged_frames[merge_round][idx]\n",
    "    mr = all_merged_records[merge_round][idx]\n",
    "    renamed = mr.copy()\n",
    "    renamed.name = 'merged'\n",
    "    return umf.append(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.402271Z",
     "start_time": "2020-11-15T16:28:50.831Z"
    }
   },
   "outputs": [],
   "source": [
    "show_merge(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 5. Add new columns, rename/reorder, otherwise finalize dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 5a. New columns and bookkeeping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column for the time (in days) between incarceration (or incident) and death\n",
    "Note: for a few of these, the death date/time is before the incarceration/incident date. If they are only one day apart, we just call it 0 and assume it was a minor error. If they are more than a day apart, clearly there was a larger error, so we use a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.404019Z",
     "start_time": "2020-11-15T16:28:50.835Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.date_time_of_custody_or_incident.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.405796Z",
     "start_time": "2020-11-15T16:28:50.838Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_days(dt):\n",
    "    if dt.days < -1:\n",
    "        return None\n",
    "    elif dt.days == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return dt.days\n",
    "\n",
    "delta = cdr.death_date_and_time - cdr.date_time_of_custody_or_incident\n",
    "print(\"For %d records with death date before custoday date, setting the days_from_custody_to_death to NaN\" % (delta.dt.days < -1).sum())\n",
    "cdr['days_from_custody_to_death'] = delta.apply(get_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.408075Z",
     "start_time": "2020-11-15T16:28:50.841Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['suffix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.409933Z",
     "start_time": "2020-11-15T16:28:50.844Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['name_full'] = ''\n",
    "for col in ['first_name', 'middle_name', 'last_name']:\n",
    "    cdr['name_full'] = cdr['name_full'] + ' ' + cdr[col].fillna('')\n",
    "cdr['name_full'] = cdr['name_full'].apply(lambda s: ' '.join(s.strip().split()))\n",
    "cdr.loc[cdr['name_full'] == '', 'name_full'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak bookkeping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.411880Z",
     "start_time": "2020-11-15T16:28:50.847Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr['num_revisions'] = cdr['version_number'] - 1\n",
    "cdr.drop(['version_type', 'version_number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 5b. Rename and reorder columns sensibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.413258Z",
     "start_time": "2020-11-15T16:28:50.851Z"
    }
   },
   "outputs": [],
   "source": [
    "col_renames = {\n",
    "    'first_name': 'name_first',\n",
    "    'middle_name': 'name_middle',\n",
    "    'last_name': 'name_last',\n",
    "    'suffix': 'name_suffix',\n",
    "    'cdr_cdr_name': 'record_id',\n",
    "    'death_causer_other': 'who_caused_death_in_homicide_or_accident_other',\n",
    "    'who_caused_the_death': 'who_caused_death_in_homicide_or_accident',\n",
    "    'death_location': 'death_location_type',\n",
    "    'death_location_elsewhere': 'death_location_type_other',\n",
    "    'city': 'death_location_city',\n",
    "    'county': 'death_location_county',\n",
    "    'street_address': 'death_location_street_address',\n",
    "    'entry_date_time': 'facility_entry_date_time',\n",
    "    'pre_existing_medical_condition': 'death_from_pre_existing_medical_condition',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.415041Z",
     "start_time": "2020-11-15T16:28:50.854Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.rename(columns=col_renames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.416757Z",
     "start_time": "2020-11-15T16:28:50.857Z"
    }
   },
   "outputs": [],
   "source": [
    "new_order = [\n",
    "    # Record indexing columns\n",
    "    'record_id',\n",
    "    'num_revisions',\n",
    "    'form_version',\n",
    "    'report_date',\n",
    "    'date_time_of_custody_or_incident',\n",
    "\n",
    "    # Deceased personal information, demographics\n",
    "    'name_first',\n",
    "    'name_last',\n",
    "    'name_middle',\n",
    "    'name_suffix',\n",
    "    'name_full',\n",
    "    'date_of_birth',\n",
    "    'age_at_time_of_death',\n",
    "    'sex',\n",
    "    'race',\n",
    "\n",
    "    # Death event information\n",
    "    'death_date',\n",
    "    'death_date_and_time',\n",
    "    'death_location_county',\n",
    "    'death_location_city',\n",
    "    'death_location_street_address',\n",
    "    'death_location_type',\n",
    "    'death_location_type_other',\n",
    "    'death_from_pre_existing_medical_condition',\n",
    "    'manner_of_death',\n",
    "    'manner_of_death_description',\n",
    "    'means_of_death',\n",
    "    'means_of_death_other',\n",
    "    'medical_cause_of_death',\n",
    "    'medical_examinor_coroner_evalution',\n",
    "    'medical_treatment',\n",
    "    'days_from_custody_to_death',\n",
    "    'who_caused_death_in_homicide_or_accident',\n",
    "    'who_caused_death_in_homicide_or_accident_other',\n",
    "\n",
    "    # Criminal information on deceased\n",
    "    'offense_1',\n",
    "    'offense_2',\n",
    "    'offense_3',\n",
    "    'type_of_offense',\n",
    "    'type_of_offense_other',\n",
    "    'were_the_charges',\n",
    "\n",
    "    # Facility and agency information\n",
    "    'facility_entry_date_time',\n",
    "    'type_of_custody',\n",
    "    'specific_type_of_custody_facility',\n",
    "    'agency_address',\n",
    "    'agency_city',\n",
    "    'agency_county',\n",
    "    'agency_name',\n",
    "    'agency_zip',\n",
    "    \n",
    "    # Deceased behavior upon entry or custody\n",
    "    'type_of_restraint',\n",
    "    'under_restraint',\n",
    "    'entry_behavior',\n",
    "    'other_behavior',\n",
    "    'exhibit_any_medical_problems',\n",
    "    'exhibit_any_mental_health_problems',\n",
    "    'make_suicidal_statements',\n",
    "]\n",
    "\n",
    "cdr = reorder_columns_and_check(cdr, new_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #008;height: 15px\"></div>\n",
    "\n",
    "## 5c. Final look before writing (NO CHANGES from here until writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.418270Z",
     "start_time": "2020-11-15T16:28:50.861Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.420060Z",
     "start_time": "2020-11-15T16:28:50.864Z"
    }
   },
   "outputs": [],
   "source": [
    "show_notnull_chart(cdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.421697Z",
     "start_time": "2020-11-15T16:28:50.867Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(cdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.423474Z",
     "start_time": "2020-11-15T16:28:50.869Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.form_version.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.425778Z",
     "start_time": "2020-11-15T16:28:50.872Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.death_date.apply(lambda dt: dt.year), cdr.form_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more duplication sanity check -- any CDRs with the same name since 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.427407Z",
     "start_time": "2020-11-15T16:28:50.876Z"
    }
   },
   "outputs": [],
   "source": [
    "f = cdr[cdr.death_date.apply(lambda dt: dt.year) >= 2018]\n",
    "vc = f['name_full'].value_counts()\n",
    "vc[vc > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at these cases, they seem fine. Just name coincidences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.429017Z",
     "start_time": "2020-11-15T16:28:50.880Z"
    }
   },
   "outputs": [],
   "source": [
    "f[f['name_full'] == 'RENE GARCIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.430858Z",
     "start_time": "2020-11-15T16:28:50.883Z"
    }
   },
   "outputs": [],
   "source": [
    "f[f['name_full'] == 'JOSE RIOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #080;height: 20px\"></div>\n",
    "\n",
    "# 6. Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.432562Z",
     "start_time": "2020-11-15T16:28:50.886Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.environ.get('CLEAN_CDR_DW') != 'TRUE':\n",
    "    print(\"Not syncing to Data.world. To do so, set CLEAN_CDR_DW to 'TRUE'\")\n",
    "else:\n",
    "    with dw.open_remote_file(OUTPUT_DW_PROJECT, OUTPUT_FILENAME) as w:\n",
    "        print(\"Writing to data.world:\", OUTPUT_FILENAME)\n",
    "        cdr.to_csv(w, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.434181Z",
     "start_time": "2020-11-15T16:28:50.889Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.environ.get('CLEAN_CDR_S3') != 'TRUE':\n",
    "    print(\"Not writing to s3. To do so, set CLEAN_CDR_S3 to 'TRUE'\")\n",
    "else:\n",
    "    csv_buffer = StringIO()\n",
    "    cdr.to_csv(csv_buffer, index=False)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object('tji-public-cleaned-datasets', OUTPUT_FILENAME).put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color: #A0A;height: 20px\"></div>\n",
    "\n",
    "# 7. TODOs -- problems that still exist in the data and need work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] `age_at_time_of_death` and `date_of_birth` can sometimes be impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.435537Z",
     "start_time": "2020-11-15T16:28:50.894Z"
    }
   },
   "outputs": [],
   "source": [
    "cdr.age_at_time_of_death[cdr.age_at_time_of_death < 0].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.436961Z",
     "start_time": "2020-11-15T16:28:50.897Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"%d records have a birth date AFTER death date\" % (cdr.date_of_birth > cdr.death_date).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] `type_of_offense` is a semicolon-separated list. Break this into multiple binary columns? Or reduce to only the most serious type? Unclear what to do if want to actually USE this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.438153Z",
     "start_time": "2020-11-15T16:28:50.900Z"
    }
   },
   "outputs": [],
   "source": [
    "s = cdr.type_of_offense\n",
    "print(\"%d unique values for type_of_offense. Sample below:\" % len(set(cdr.type_of_offense)))\n",
    "s.value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.439514Z",
     "start_time": "2020-11-15T16:28:50.903Z"
    }
   },
   "outputs": [],
   "source": [
    "s = cdr.type_of_offense_other\n",
    "print(\"%d unique values for type_of_offense_other. Sample below:\" % len(set(cdr.type_of_offense_other)))\n",
    "s.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Manner of death is sometimes 'OTHER' when it should not be\n",
    "Two columns detail the manner of death: `manner_of_death` and `manner_of_death_description`. A handful of rows have `manner_of_death` = `OTHER` when they should have picked `ACCIDENT` or `HOMICIDE` -- as evinced by the information in the `manner_of_death_description` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.441048Z",
     "start_time": "2020-11-15T16:28:50.907Z"
    }
   },
   "outputs": [],
   "source": [
    "frame = cdr[(cdr.manner_of_death == OTHER_SPECIFY) & (cdr.manner_of_death_description.notnull())]\n",
    "for exempt in ('PENDING', 'DETERMIN'):\n",
    "    frame = frame[~frame.manner_of_death_description.str.contains(exempt)]\n",
    "print(len(frame), len(cdr))\n",
    "frame[['form_version', 'manner_of_death_description', 'manner_of_death', 'medical_cause_of_death']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] (Related) Extract motor vehicle accidents into a unique type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.442976Z",
     "start_time": "2020-11-15T16:28:50.910Z"
    }
   },
   "outputs": [],
   "source": [
    "# This starter code should get it going\n",
    "frame = cdr[(cdr.manner_of_death != 'ACCIDENTAL')]\n",
    "frame = frame[(frame.medical_cause_of_death.fillna('').str.contains('ACCIDENT')) |\n",
    "              frame.manner_of_death_description.fillna('').str.contains('ACCIDENT')]\n",
    "print(len(frame))\n",
    "frame[['medical_cause_of_death', 'means_of_death', 'means_of_death_other', 'manner_of_death', 'manner_of_death_description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Remove `medical_examinor_coroner_evalution`? Not sure it's useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.444665Z",
     "start_time": "2020-11-15T16:28:50.914Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.medical_examinor_coroner_evalution, cdr.form_version).sort_values(['V_2005'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Somehow blend the `entry_behavior`/`other_behavior` field from V_2005 with the `exhibit_any_medical_problems`, `exhibit_any_mental_health_problems` and `make_suicidal_statements` from V_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.446379Z",
     "start_time": "2020-11-15T16:28:50.918Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.entry_behavior, cdr.form_version).sort_values(['V_2005'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.447658Z",
     "start_time": "2020-11-15T16:28:50.921Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.exhibit_any_medical_problems, cdr.form_version).sort_values(['V_2016'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.448917Z",
     "start_time": "2020-11-15T16:28:50.924Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.exhibit_any_mental_health_problems, cdr.form_version).sort_values(['V_2016'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.450358Z",
     "start_time": "2020-11-15T16:28:50.926Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cdr.make_suicidal_statements, cdr.form_version).sort_values(['V_2016'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] Align various binary behavioral columns across form versions so we can keep them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T16:28:56.451836Z",
     "start_time": "2020-11-15T16:28:50.930Z"
    }
   },
   "outputs": [],
   "source": [
    "# These columns were completely removed. Some can stay once paired off\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
