{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch a suite of Census data about Texas counties\n",
    "\n",
    "#### Uses Census quickfacts, e.g. https://www.census.gov/quickfacts/fact/table/andrewscountytexas\n",
    "\n",
    "* Input: `texas_counties.csv`\n",
    "* Output: `census_texas_counties.csv`\n",
    "\n",
    "Author: Everett Wetchler (everett.wetchler@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DTW_PROJECT_KEY = 'tji/auxiliary-datasets'\n",
    "COUNTY_INPUT_DATAFRAME_NAME = 'texas_counties'\n",
    "OUTPUT_FILENAME = 'census_texas_counties.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everett Wetchler 2018-04-28 13:22:51 CDT\n",
      "\n",
      "datadotworld 1.6.0\n",
      "numpy 1.14.2\n",
      "pandas 0.20.1\n",
      "watermark 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import datadotworld as dw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Everett Wetchler\" -d -t -z -w -p datadotworld,numpy,pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data.world\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading from data.world\")\n",
    "datasets = dw.load_dataset(DTW_PROJECT_KEY, force_update=True)\n",
    "COUNTY_NAMES = sorted(list(datasets.dataframes[COUNTY_INPUT_DATAFRAME_NAME]['county']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_metrics(soup):\n",
    "    '''Given the BeautifulSoup for a census page, extract a metrics dictionary.'''\n",
    "    metrics = {}\n",
    "    missing = 0\n",
    "    sections = soup.find_all('caption')\n",
    "    for sec in sections:\n",
    "        sec_title = sec.text.strip()\n",
    "        subsections = sec.parent.find_all('tr', attrs={'class': 'qf-header'})\n",
    "        for sub in subsections:\n",
    "            sub_title = sub.text.strip()\n",
    "            for i, r in enumerate(sub.parent.find_all('tr', attrs={'class': 'fact'})):\n",
    "                cells = r.find_all('td')\n",
    "                metric = ' '.join(elt for elt in cells[0].find('span').children\n",
    "                                  if isinstance(elt, bs4.element.NavigableString))\n",
    "                key = (sec_title, sub_title, metric)\n",
    "                value = float(cells[1].attrs['data-value'])\n",
    "                if int(cells[1].attrs['data-isnumeric']) != 1:\n",
    "                    value = np.nan\n",
    "                    missing += 1\n",
    "                else:\n",
    "                    assert(not np.isnan(value))\n",
    "                metrics[key] = value\n",
    "\n",
    "#     print(f'{len(metrics)} metric names found, {missing} of those were missing values')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_one(location, is_county=True, return_soup=False):\n",
    "    '''Fetch the census data for a given Texas county.'''\n",
    "    url = 'https://www.census.gov/quickfacts/fact/table/' + location.lower().replace(' ', '')\n",
    "    if is_county:\n",
    "        url = url + 'countytexas'\n",
    "#     print('> Fetching', url)\n",
    "    res = s.get(url)\n",
    "    res.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    for elt in soup.find_all('div', attrs={'class': 'qf-geobox'}):\n",
    "        if elt.text.strip():\n",
    "            title = elt.text.strip().upper()\n",
    "            break\n",
    "    if title == 'UNITED STATES':\n",
    "        raise Exception(\"Could not find data for data for %s\" % (location))\n",
    "    if return_soup:\n",
    "        return soup, extract_metrics(soup)\n",
    "    else:\n",
    "        return extract_metrics(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching census data for 254 counties\n",
      "\n",
      "[1]ANDERSON [2]ANDREWS [3]ANGELINA [4]ARANSAS [5]ARCHER [6]ARMSTRONG [7]ATASCOSA [8]AUSTIN [9]BAILEY [10]BANDERA [11]BASTROP [12]BAYLOR [13]BEE [14]BELL [15]BEXAR [16]BLANCO [17]BORDEN [18]BOSQUE [19]BOWIE [20]BRAZORIA [21]BRAZOS [22]BREWSTER [23]BRISCOE [24]BROOKS [25]BROWN [26]BURLESON [27]BURNET [28]CALDWELL [29]CALHOUN [30]CALLAHAN [31]CAMERON [32]CAMP [33]CARSON [34]CASS [35]CASTRO [36]CHAMBERS [37]CHEROKEE [38]CHILDRESS [39]CLAY [40]COCHRAN [41]COKE [42]COLEMAN [43]COLLIN [44]COLLINGSWORTH [45]COLORADO [46]COMAL [47]COMANCHE [48]CONCHO [49]COOKE [50]CORYELL [51]COTTLE [52]CRANE [53]CROCKETT [54]CROSBY [55]CULBERSON [56]DALLAM [57]DALLAS [58]DAWSON [59]DEAF SMITH [60]DELTA [61]DENTON [62]DEWITT [63]DICKENS [64]DIMMIT [65]DONLEY [66]DUVAL [67]EASTLAND [68]ECTOR [69]EDWARDS [70]EL PASO [71]ELLIS [72]ERATH [73]FALLS [74]FANNIN [75]FAYETTE [76]FISHER [77]FLOYD [78]FOARD [79]FORT BEND [80]FRANKLIN [81]FREESTONE [82]FRIO [83]GAINES [84]GALVESTON [85]GARZA [86]GILLESPIE [87]GLASSCOCK [88]GOLIAD [89]GONZALES [90]GRAY [91]GRAYSON [92]GREGG [93]GRIMES [94]GUADALUPE [95]HALE [96]HALL [97]HAMILTON [98]HANSFORD [99]HARDEMAN [100]HARDIN [101]HARRIS [102]HARRISON [103]HARTLEY [104]HASKELL [105]HAYS [106]HEMPHILL [107]HENDERSON [108]HIDALGO [109]HILL [110]HOCKLEY [111]HOOD [112]HOPKINS [113]HOUSTON [114]HOWARD [115]HUDSPETH [116]HUNT [117]HUTCHINSON [118]IRION [119]JACK [120]JACKSON [121]JASPER [122]JEFF DAVIS [123]JEFFERSON [124]JIM HOGG [125]JIM WELLS [126]JOHNSON [127]JONES [128]KARNES [129]KAUFMAN [130]KENDALL [131]KENEDY [132]KENT [133]KERR [134]KIMBLE [135]KING [136]KINNEY [137]KLEBERG [138]KNOX [139]LA SALLE [140]LAMAR [141]LAMB [142]LAMPASAS [143]LAVACA [144]LEE [145]LEON [146]LIBERTY [147]LIMESTONE [148]LIPSCOMB [149]LIVE OAK [150]LLANO [151]LOVING [152]LUBBOCK [153]LYNN [154]MADISON [155]MARION [156]MARTIN [157]MASON [158]MATAGORDA [159]MAVERICK [160]MCCULLOCH [161]MCLENNAN [162]MCMULLEN [163]MEDINA [164]MENARD [165]MIDLAND [166]MILAM [167]MILLS [168]MITCHELL [169]MONTAGUE [170]MONTGOMERY [171]MOORE [172]MORRIS [173]MOTLEY [174]NACOGDOCHES [175]NAVARRO [176]NEWTON [177]NOLAN [178]NUECES [179]OCHILTREE [180]OLDHAM [181]ORANGE [182]PALO PINTO [183]PANOLA [184]PARKER [185]PARMER [186]PECOS [187]POLK [188]POTTER [189]PRESIDIO [190]RAINS [191]RANDALL [192]REAGAN [193]REAL [194]RED RIVER [195]REEVES [196]REFUGIO [197]ROBERTS [198]ROBERTSON [199]ROCKWALL [200]RUNNELS [201]RUSK [202]SABINE [203]SAN AUGUSTINE [204]SAN JACINTO [205]SAN PATRICIO [206]SAN SABA [207]SCHLEICHER [208]SCURRY [209]SHACKELFORD [210]SHELBY [211]SHERMAN [212]SMITH [213]SOMERVELL [214]STARR [215]STEPHENS [216]STERLING [217]STONEWALL [218]SUTTON [219]SWISHER [220]TARRANT [221]TAYLOR [222]TERRELL [223]TERRY [224]THROCKMORTON [225]TITUS [226]TOM GREEN [227]TRAVIS [228]TRINITY [229]TYLER [230]UPSHUR [231]UPTON [232]UVALDE [233]VAL VERDE [234]VAN ZANDT [235]VICTORIA [236]WALKER [237]WALLER [238]WARD [239]WASHINGTON [240]WEBB [241]WHARTON [242]WHEELER [243]WICHITA [244]WILBARGER [245]WILLACY [246]WILLIAMSON [247]WILSON [248]WINKLER [249]WISE [250]WOOD [251]YOAKUM [252]YOUNG [253]ZAPATA [254]ZAVALA \n",
      "***** 0 failure(s): []\n"
     ]
    }
   ],
   "source": [
    "failures = []\n",
    "s = requests.Session()\n",
    "\n",
    "print(f\"Fetching census data for {len(COUNTY_NAMES)} counties\\n\")\n",
    "\n",
    "for i, county in enumerate(COUNTY_NAMES):\n",
    "    if county in county_metrics:\n",
    "        # Useful if you have to pause the script and restart it.\n",
    "        continue\n",
    "#     print(\"--- Pulling data for %s county (%d/%d) ---\" % (county, i+1, len(COUNTY_NAMES)))\n",
    "    print(f\"[{i+1}]{county}\", end=' ')\n",
    "    metrics = fetch_one(county)\n",
    "    if metrics:\n",
    "        county_metrics[county] = metrics\n",
    "    else:\n",
    "        failures.append(county)\n",
    "\n",
    "print(\"\\n***** %d failure(s):\" % len(failures), failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for the full state of Texas\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching data for the full state of Texas\")\n",
    "texas = fetch_one('TX', is_county=False)\n",
    "if not texas:\n",
    "    raise Exception('Could not get Texas state-wide data')\n",
    "\n",
    "# The state-level data has some extra measurements, which we'll drop\n",
    "to_delete = set(texas) - set(county_metrics['ANDERSON'])\n",
    "for d in to_delete:\n",
    "    del texas[d]\n",
    "\n",
    "county_metrics['_ALL_TEXAS'] = texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(county_metrics).sort_index()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next two cells just unpack the multi-level index into three distinct columns (with sensible names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_col_front(df, s, name):\n",
    "    cols = list(df.columns)\n",
    "    newcols = [name] + cols\n",
    "    df[name] = s\n",
    "    return df[newcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = insert_col_front(df, df.index.get_level_values(2), 'metric_description')\n",
    "df = insert_col_front(df, df.index.get_level_values(1), 'metric_subcategory')\n",
    "df = insert_col_front(df, df.index.get_level_values(0), 'metric_category')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to data.world\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing to data.world\")\n",
    "with dw.open_remote_file(DTW_PROJECT_KEY, OUTPUT_FILENAME) as w:\n",
    "    df.to_csv(w, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
